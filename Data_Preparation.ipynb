{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3afd14ba-6dea-45e2-bffc-e313c23e0f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 23:15:08.415108: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 2 classes.\n",
      "Found 587 files belonging to 2 classes.\n",
      "Found 585 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling, RandomZoom\n",
    "from code.data_loader import get_datasets\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.metrics import Recall\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration settings\n",
    "config = {\n",
    "    \"batch_size\": 64,\n",
    "    \"image_size\": (64, 64),\n",
    "    \"color_mode\": \"grayscale\",\n",
    "    \"label_mode\": \"binary\",\n",
    "    \"shuffle_buffer_size\": 1000\n",
    "}\n",
    "\n",
    "# Creating a Rescaling layer externally\n",
    "rescaling_layer = Rescaling(1./255)\n",
    "\n",
    "# Directories\n",
    "directories = {\n",
    "    \"train\": \"data/chest_xray/new_train\",\n",
    "    \"test\": \"data/chest_xray/new_test\",\n",
    "    \"val\": \"data/chest_xray/new_val\"\n",
    "}\n",
    "\n",
    "# Loading datasets with external preprocessing\n",
    "train_ds, test_ds, val_ds = get_datasets(directories, config, preprocessing_layer=rescaling_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618dd6e-6d12-4a63-8c75-124a5ba31028",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preparation\n",
    "\n",
    "Describe and justify the process for preparing the data for analysis.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* Were there variables you dropped or created?\n",
    "* How did you address missing values or outliers?\n",
    "* Why are these choices appropriate given the data and the business problem?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54dc7f-ee15-4859-a3ce-98e7c216af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import image_dataset_from_director\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras.regularizers import l1, l2\n",
    "# from tensorflow.keras import layers\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# import time\n",
    "# import random\n",
    "# random.seed(42)\n",
    "# import numpy as np\n",
    "# np.random.seed(42)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape= (64, 64, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=Recall(name='recall'))\n",
    "    \n",
    "history = model.fit(train_ds,\n",
    "                    epochs=50,\n",
    "                    validation_data=val_ds,\n",
    "                    verbose=0)\n",
    "        \n",
    "train_scores = model.evaluate(train_ds)\n",
    "val_scores = model.evaluate(val_ds)\n",
    "num_metrics = int(len(history.history.keys())/2)\n",
    "metrics_names = list(history.history.keys())[:num_metrics]\n",
    "diff_scores = [b - a for a, b in zip(train_scores, val_scores)]\n",
    "display(pd.DataFrame([train_scores,val_scores,diff_scores],index=['Train','Val','Diff'],columns=metrics_names))\n",
    "print('------------------------------')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a00743f-b856-4781-8623-2d28b2698d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', input_shape= (64, 64, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=Recall(name='recall'))\n",
    "    \n",
    "history = model.fit(train_ds,\n",
    "                    epochs=50,\n",
    "                    validation_data=val_ds,\n",
    "                    verbose=1)\n",
    "        \n",
    "train_scores = model.evaluate(train_ds)\n",
    "val_scores = model.evaluate(val_ds)\n",
    "num_metrics = int(len(history.history.keys())/2)\n",
    "metrics_names = list(history.history.keys())[:num_metrics]\n",
    "diff_scores = [b - a for a, b in zip(train_scores, val_scores)]\n",
    "display(pd.DataFrame([train_scores,val_scores,diff_scores],index=['Train','Val','Diff'],columns=metrics_names))\n",
    "print('------------------------------')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc352ea9-b9aa-4e83-a0b6-0d23621d368d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 18s 149ms/step - loss: 0.4583 - recall: 0.9210 - val_loss: 0.2251 - val_recall: 0.8852\n",
      "74/74 [==============================] - 3s 42ms/step - loss: 0.2318 - recall: 0.8996\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.2251 - recall: 0.8852\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.231767</td>\n",
       "      <td>0.899649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Val</th>\n",
       "      <td>0.225081</td>\n",
       "      <td>0.885246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diff</th>\n",
       "      <td>-0.006686</td>\n",
       "      <td>-0.014403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss    recall\n",
       "Train  0.231767  0.899649\n",
       "Val    0.225081  0.885246\n",
       "Diff  -0.006686 -0.014403"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', input_shape= (64, 64, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=Recall(name='recall'))\n",
    "    \n",
    "history = model.fit(train_ds,\n",
    "                    epochs=1,\n",
    "                    validation_data=val_ds,\n",
    "                    verbose=1)\n",
    "        \n",
    "train_scores = model.evaluate(train_ds)\n",
    "val_scores = model.evaluate(val_ds)\n",
    "num_metrics = int(len(history.history.keys())/2)\n",
    "metrics_names = list(history.history.keys())[:num_metrics]\n",
    "diff_scores = [b - a for a, b in zip(train_scores, val_scores)]\n",
    "display(pd.DataFrame([train_scores,val_scores,diff_scores],index=['Train','Val','Diff'],columns=metrics_names))\n",
    "print('------------------------------')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b730ec2-b579-4e04-bbab-d073df26faba",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define your data augmentation\n",
    "data_augmentation = Sequential([\n",
    "  layers.RandomZoom(0.3),\n",
    "  # Add more augmentation layers if needed\n",
    "])\n",
    "\n",
    "# Apply augmentation to the training dataset\n",
    "augmented_train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', input_shape= (64, 64, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=Recall(name='recall'))\n",
    "    \n",
    "history = model.fit(train_ds,\n",
    "                    epochs=1,\n",
    "                    validation_data=val_ds,\n",
    "                    verbose=1)\n",
    "        \n",
    "train_scores = model.evaluate(train_ds)\n",
    "val_scores = model.evaluate(val_ds)\n",
    "num_metrics = int(len(history.history.keys())/2)\n",
    "metrics_names = list(history.history.keys())[:num_metrics]\n",
    "diff_scores = [b - a for a, b in zip(train_scores, val_scores)]\n",
    "display(pd.DataFrame([train_scores,val_scores,diff_scores],index=['Train','Val','Diff'],columns=metrics_names))\n",
    "print('------------------------------')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abfa4ed-adc2-44da-8112-83e65ad7862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define your data augmentation\n",
    "data_augmentation = Sequential([\n",
    "  layers.RandomZoom(0.2),\n",
    "  # Add more augmentation layers if needed\n",
    "])\n",
    "\n",
    "# Apply augmentation to the training dataset\n",
    "augmented_train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "# Define the model without the RandomZoom layer\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', input_shape=(64, 64, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Recall(name='recall')])\n",
    "\n",
    "# Train with the augmented dataset\n",
    "history = model.fit(augmented_train_ds, epochs=1, validation_data=val_ds, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e08b240-b72d-405f-a2c1-4307a9ceb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # RandomZoom(0.3),\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',input_shape=(64, 64, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    Dropout(0.5),  \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=Recall(name='recall'))\n",
    "    \n",
    "history = model.fit(train_ds,\n",
    "                    epochs=76,\n",
    "                    validation_data=val_ds,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845dc781-d20b-4bea-9a88-a7f896d44e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = model.evaluate(train_ds)\n",
    "val_scores = model.evaluate(val_ds)\n",
    "num_metrics = int(len(history.history.keys())/2)\n",
    "metrics_names = list(history.history.keys())[:num_metrics]\n",
    "diff_scores = [b - a for a, b in zip(train_scores, val_scores)]\n",
    "display(pd.DataFrame([train_scores,val_scores,diff_scores],index=['Train','Val','Diff'],columns=metrics_names))\n",
    "print('------------------------------')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740bd7e9-fddf-4e60-b5df-23938a7a2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Modeling\n",
    "Describe and justify the process for analyzing or modeling the data.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "How did you analyze or model the data?\n",
    "How did you iterate on your initial approach to make it better?\n",
    "Why are these choices appropriate given the data and the business problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfce15d-9157-4298-9b1a-7309dee45b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "Evaluate how well your work solves the stated business problem.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* How do you interpret the results?\n",
    "* How well does your model fit your data? How much better is this than your baseline model?\n",
    "* How confident are you that your results would generalize beyond the data you have?\n",
    "* How confident are you that this model would benefit the business if put into use?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4160e72e-47d9-4104-aa19-16ac49955782",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusions\n",
    "Provide your conclusions about the work you've done, including any limitations or next steps.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* What would you recommend the business do as a result of this work?\n",
    "* What are some reasons why your analysis might not fully solve the business problem?\n",
    "* What else could you do in the future to improve this project?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9cf521-28de-47ac-80b7-120d9b16acdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637ef1e-e402-435a-99a6-30463e2a2c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003ffd5-eb0d-40c8-9990-f272b606c85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6884f0-ec9e-42cf-9fdb-ae9c7856b119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
